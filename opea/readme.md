# Exploring Opea

OPEA - OPEA (Open Platform for Enterprise AI) is a framework that enables the creation and evaluation of open, multi-provider, robust, and composable generative AI (GenAI) solutions. It harnesses the best innovations across the ecosystem while keeping enterprise-level needs front and center.

https://opea-project.github.io/latest/index.html

## Business Goal
The company wants you to explore the effort it would take to run the AI workloads completely on servers that will live in-house. The fractional CTO, suggests that its best practice to run workloads in containers or kubenetes. **You as the AI Engineer have been tasked to determine how to learn to work with the building blocks to constructor your own GenAI workloads running on containers.**

### Technical Understanding 

 OPEA has a set of templates of Microservices designed specific to perform a function or task withing the application architecture - **As per our business goal, it suits well with our requirement of running the components in our containers**

#### Tasks 

1.  Choose one particular OPEA component & try analysing the code to explore deep

    - Outcome - This will give you a basic sketch on how OPEA comps are structured & document it

    - [Result](task-1/readme.md)

2. Try orchestrating multiple services together - Choose a megaservice and try deploying in local machine

    - Outcome - How megaservice orchestrated multiple services together, document it

3. Final documentation

    - Outcome - Make a tutorial or  techincal documentation on overall understanding


### Technical Uncertainities 

- Is the microservices works in basic developer machine, Mac M1 pro in my case?
- How's stable is the environment is, does the microservices architecture basic principles are followed?


